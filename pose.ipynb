{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-22T11:32:39.914400Z","iopub.status.busy":"2023-08-22T11:32:39.914017Z","iopub.status.idle":"2023-08-22T11:32:40.425862Z","shell.execute_reply":"2023-08-22T11:32:40.424412Z","shell.execute_reply.started":"2023-08-22T11:32:39.914372Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","        break\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:32:40.429146Z","iopub.status.busy":"2023-08-22T11:32:40.428530Z","iopub.status.idle":"2023-08-22T11:32:40.443808Z","shell.execute_reply":"2023-08-22T11:32:40.442485Z","shell.execute_reply.started":"2023-08-22T11:32:40.429088Z"},"trusted":true},"outputs":[],"source":["dataset = pd.read_csv('kaggle/input/ukraine-ml-bootcamp-2023/train.csv').to_numpy()\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:32:40.445678Z","iopub.status.busy":"2023-08-22T11:32:40.445342Z","iopub.status.idle":"2023-08-22T11:32:40.452031Z","shell.execute_reply":"2023-08-22T11:32:40.450512Z","shell.execute_reply.started":"2023-08-22T11:32:40.445649Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import os\n","import tensorflow as tf\n","from PIL import Image\n","import keras\n","import cv2\n","import mediapipe as mp"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For finding pose cords\n","mp_pose = mp.solutions.pose\n","\n","pose_detector = mp_pose.Pose(\n","    static_image_mode=True,\n","    min_detection_confidence=0.0,\n","    min_tracking_confidence=0.0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img = Image.open('kaggle/input/ukraine-ml-bootcamp-2023/images/train_images/1684a6b47dd92daca9b0803d18f1285a.jpg')\n","img = np.array(img.resize((160, 160)))\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def image_to_pose_cords(img):\n","    results = pose_detector.process(np.array(img))\n","    if results.pose_landmarks is None:\n","        array = np.zeros((33, 4))\n","    else:\n","        a = results.pose_landmarks.ListFields()[0][1]\n","        array = []\n","        for val in a:\n","            array.append([val.x, val.y, val.z, val.visibility])\n","    \n","    np.expand_dims(array, -1)\n","    return array"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_cords = np.array(image_to_pose_cords(img))\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(projection='3d')\n","\n","for m, zlow, zhigh in [('o', -50, -25), ('^', -30, -5)]:\n","    ax.scatter(test_cords[:, 0], test_cords[:, 1], test_cords[:, 2], marker=m)\n","\n","ax.set_xlabel('X Label')\n","ax.set_ylabel('Y Label')\n","ax.set_zlabel('Z Label')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:32:40.899777Z","iopub.status.busy":"2023-08-22T11:32:40.899412Z","iopub.status.idle":"2023-08-22T11:33:21.660851Z","shell.execute_reply":"2023-08-22T11:33:21.659663Z","shell.execute_reply.started":"2023-08-22T11:32:40.899743Z"},"trusted":true},"outputs":[],"source":["# Create array with all images\n","img_data = []\n","pose_data = []\n","\n","data_dir = 'kaggle/input/ukraine-ml-bootcamp-2023/images/train_images/'\n","BATCH_SIZE = 64\n","IMG_SIZE = (224, 224)\n","\n","from image_preprocessing import get_train_ds\n","\n","# ds = get_train_ds(dataset, data_dir, IMG_SIZE, False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# img_data = []\n","# pose_data = []\n","# for pose, cords in ds:\n","#     img_data.append(cords)\n","#     pose_data.append(pose)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:33:21.662816Z","iopub.status.busy":"2023-08-22T11:33:21.662472Z","iopub.status.idle":"2023-08-22T11:33:21.811165Z","shell.execute_reply":"2023-08-22T11:33:21.809601Z","shell.execute_reply.started":"2023-08-22T11:33:21.662786Z"},"trusted":true},"outputs":[],"source":["# img_data = np.array(img_data)\n","# pose_data = np.array(pose_data)\n","# pose_data_ohe = np.array(tf.one_hot(pose_data, 6))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# np.save('pose_arrays/pose_data_ohe.npy', pose_data_ohe)\n","# np.save('pose_arrays/img_data.npy', img_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pose_data_ohe = np.load('pose_arrays/pose_data_ohe.npy')\n","img_data = np.load('pose_arrays/img_data.npy')\n","print(img_data.shape, pose_data_ohe.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:33:21.813804Z","iopub.status.busy":"2023-08-22T11:33:21.813369Z","iopub.status.idle":"2023-08-22T11:33:22.034267Z","shell.execute_reply":"2023-08-22T11:33:22.033025Z","shell.execute_reply.started":"2023-08-22T11:33:21.813769Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(img_data, pose_data_ohe, train_size=0.9)\n","print(len(X_train), len(X_test))"]},{"cell_type":"markdown","metadata":{},"source":["# Model definition"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:33:23.468106Z","iopub.status.busy":"2023-08-22T11:33:23.467710Z","iopub.status.idle":"2023-08-22T11:33:23.609135Z","shell.execute_reply":"2023-08-22T11:33:23.608021Z","shell.execute_reply.started":"2023-08-22T11:33:23.468073Z"},"trusted":true},"outputs":[],"source":["from keras.layers import Conv1D, Conv2D,MaxPooling2D, Flatten, Dense, Dropout, SimpleRNN\n","model = keras.Sequential([\n","    keras.Input((33, 4, 1)),\n","    Conv2D(64, (4, 4), activation='relu'),\n","    Conv2D(128, (4, 1), activation='relu'),\n","    # MaxPooling2D(2, 2),\n","    # Conv2D(32, (2, 4), activation='relu'),\n","    # Conv1D(128, (4), activation='relu',),\n","    # Conv2D(64, (2, 2), activation='relu'),\n","    # Conv1D(64, (2), activation='relu', input_shape=(33, 4, 1)),\n","    # MaxPooling2D(2, 2),\n","    Flatten(),\n","    # Dense(256, activation='relu', input_shape=(33, 4)),\n","    Dense(256, activation='relu'),\n","    Dense(256, activation='relu'),\n","    Dense(256, activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(64, activation='relu'),\n","    Dense(6, activation='softmax')\n","])"]},{"cell_type":"markdown","metadata":{},"source":["# Training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:33:23.610816Z","iopub.status.busy":"2023-08-22T11:33:23.610491Z","iopub.status.idle":"2023-08-22T11:33:23.617522Z","shell.execute_reply":"2023-08-22T11:33:23.616488Z","shell.execute_reply.started":"2023-08-22T11:33:23.610788Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import ReduceLROnPlateau\n","lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n","checkpoint = keras.callbacks.ModelCheckpoint('model.h15', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n","early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:33:23.619242Z","iopub.status.busy":"2023-08-22T11:33:23.618878Z","iopub.status.idle":"2023-08-22T11:33:23.645588Z","shell.execute_reply":"2023-08-22T11:33:23.644376Z","shell.execute_reply.started":"2023-08-22T11:33:23.619215Z"},"trusted":true},"outputs":[],"source":["learning_rate = 3e-3\n","model.compile(loss=\"categorical_crossentropy\", \n","              optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n","              metrics=[\"accuracy\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T11:33:23.647748Z","iopub.status.busy":"2023-08-22T11:33:23.647288Z"},"trusted":true},"outputs":[],"source":["history = model.fit(X_train,\n","                    y_train,\n","                    batch_size=BATCH_SIZE,\n","                    epochs=200,\n","                    validation_data=(X_test, y_test),\n","                    callbacks=[early_stop, checkpoint])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training & validation accuracy, F1 score, and loss values\n","plt.figure(figsize=(15, 5))\n","\n","# Plotting Accuracy\n","plt.subplot(1, 3, 1)\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","# Plotting Loss\n","plt.subplot(1, 3, 2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Creating predictions submissions file"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.load_weights('model.h15')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load sample submission, change values to model forecasts\n","test_data_dir = 'kaggle/input/ukraine-ml-bootcamp-2023/images/test_images/'\n","\n","df = pd.read_csv('kaggle/input/ukraine-ml-bootcamp-2023/sample_submission.csv')\n","\n","for i, (name, pose) in enumerate(df.to_numpy()):\n","    img_path = os.path.join(test_data_dir, name)\n","    img = preprocess_path(img_path)\n","    cords = image_to_pose_cords(img)\n","    pose_model = model.predict(np.array([cords]), verbose=0)[0]\n","    if i < 5:\n","        print(pose_model)\n","    df.at[i,'class_6'] = np.argmax(pose_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
